{
  "model": "attention",
  "data_dim": 32,
  "seq_len": 1,
  "batch_size": 32,
  "dataset": "data/hollywood",
  "lr": 0.0005,
  "log_dir": "experiments/attention-1638967433"
}